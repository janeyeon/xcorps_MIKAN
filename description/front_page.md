# 1. MIKAN의 목표

인공지능 의료 비서를 목표로 하여 개발을 시작하였습니다. 대학병원과 일반 의료 병원과의 점점 벌어지는 격차와 간호사들의 직장 내에서 발생하는 인권침해를 줄이기 위하여 다음과 같이 계획하였습니다. 1. 초기의 질병에 대한 간단한 문답을 통하여 각 경우에 적합한 병원을 추천하여 대학병원 집중화 현상을 줄이자. 2. 간호사들이 환자나 보호자로 부터 듣는 격한 감정적 표현을 대신하여 평서문의 음성으로 바꾸어 주는 장치를 개발하자. 3. 간호사의 익명화를 위하여 실시간으로 간호사들의 얼굴을 변환하여 보다 친근한 형태로 환자들에게 다가갈 수 있도록 하자. 

 초반에는 실시간으로 영상과 음성을 변환하여 어플리케이션의 형태로 구현하는 것을 목표로 하였지만 여러가지 어려움으로 인하여 각각의 목표를 일부 수정할 필요가 있었습니다. 음성의 경우에는 실시간 음성변환과, 목소리의 감정변조 부분과 관련된 개발이 미흡한 점 등으로 실시간음성변조를 포기하고 특정 상황에서만 음성의 감정을 변조하는 결과를 낼 수 있었습니다. 영상의 경우 마찬가지로 딥러닝 모델을 이용한 실시간 변조가 아직 덜 개발되었다는 점 등으로 인하여 영상정보를 이모티콘만들기라는 task로 변형하여 진행하였습니다.

대면소통의 비중이 줄어든 사회에서 대화시 서로의 감정을 전달하는 일이 중요한 위상을 차지하고 있습니다. 개인의 특성에 맞게 이모티콘을 제작할 수 있게 되면 이모티콘을 통한 소통이 훨씬 활발해 질 것이고, 상대방에게 부정적으로 다가오지 않아 모두에게 만족감을 줄 수 있을 것이다. 

# 2. 결과

## 	a . Voice Conversion

CycleGAN-voice conversion 과 Speech Spilt 모델을 활용하여 음성의 감정변조를 진행하였다. CycleGAN은 동일한 화자를 대상으로 non-parallel dataset을 이용하여 대화 내용의 감정정보를 학습할 수 있었다. SpeechSplit 모델은 여러가지 목소리를 인코더에 통과시켜서 높낮이와 아이덴티티 리듬 내용등을 재조합하여 원래의 음성을 복원하였다. 이 모델을 이용해서 다양한 사람의 목소리를 데이터셋에 넣기도 하고, 목소리의 아이덴티티를 한 사람에서 다른 사람으로 변환할 수 도 있었다. 두 사람의 성별이 다를 경우 목소리의 음색이 잘 바뀌지 않았지만 같을 때는 음색 요소를 변환시켰을 때 다른 사람의 목소리로 알아들을 수 있을 정도로 합성된 목소리의 질이 좋았다. 따라서 감정변환을 시도할 때 같은 성별이라면 다른 사람의 목소리를 재료로 사용해도 괜찮다는 결론을 내었다. 

## 	b. Emoticon 

개인화 된 이모티콘을 만들기 위하여 사진을 그림으로, 또는 짧은 동영상을 .gif 로 표현하는 것이다. github.com에서 U-GAT-IT 코드와 arxiv.org에서 논문을 구하여 기본적인 코드를 이용하여 직접 데이터셋을 제작하여 성능을 확인하였다. 연령별 성별별 아시아인의 얼굴을 크롤링한 AFAD-dataset에서 특히 20-30세의 여성얼굴중 256x256 이상인 것들을 골라 크롭하여 훈련시켰다. 유미의 세포들 웹툰에서 256x256 얼굴 그림을 직접 캡쳐하여 훈련시켰고, 20개의 validation set을 이용해 테스트 하였다. 

## 	c. Homepage

HTML 을 이용하여 전체적인 뼈대를 잡은 후에 CSS를 통해 색감과 위치등의 정보를 주었다. 그리고 백엔드를 Django로 작업하여 우리가 만든 모델을 홈페이지 내에서 직접 돌릴 수 있도록 추가적인 작업을 실시하였다. 

# 3. 추후 계획 

일정한 그림체의 웹툰을 데이터셋으로 활용했을 때 사진을 그 그림체에 맞게 변화시키는지 확인해보았다. 이 연구의 기대효과는 헤어스타일 등의 정보가 보존되어야 개인화된 이모티콘을 제작했을 때 사용자들이 자동으로 얻어진 이모티콘을 보고 자기 자신이라고 생각할 수 있을 것이다. 따라서 특성을 classification하고 그 정보를 최종 결과물을 만들 때 함께 넣어주는 형태의 구조를 제작하면 현재 사용한 U-GAT-IT에서 더 발전시킬 수 있을 것이다. 

시간으로 음성과 이미지 변환이 가능하다는 전제하에 영상으로 상호작용하는 가상비서의 익명성을 보호하고 목소리에 긍정적인 감정을 넣을 수 있도록
하였으나, 리얼타임 수준의 변환이 어려웠으므로 먼저 영상을 만들고 추후 그것을 이용할 수 있는 분야를 찾아보다가 이모티콘에 응용한다는 아이디어를 찾게 되었다. 코로나로 인해 비대면 산업이 활성화되면서 영상을 통한 소통의 수요도 갈수록 늘고 있으므로 결과물을 더 재생시간이 긴 영상으로 확장시킨다면 VLOG나 정보 전달용 영상을 얼굴을 노출시키지 않되 감정은 전달하는 방향으로 변환할 수 있을 것이다.